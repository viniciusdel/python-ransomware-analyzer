{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from tqdm import tqdm\n",
    "\n",
    "#Metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataframes\n",
    "df1 = pd.read_csv('ransom_csv.csv')\n",
    "df2 = pd.read_csv('benign_csv.csv')\n",
    "\n",
    "#drop extra first column\n",
    "df1 = df1.drop(df1.columns[0], axis=1)\n",
    "df2 = df2.drop(df2.columns[0], axis=1)\n",
    "\n",
    "#remove the name column (string)\n",
    "df1 = df1.drop('Name', axis=1)\n",
    "df2 = df2.drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated rows: 143 | 143\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated rows\n",
    "bool_series = df1.duplicated(keep = 'last').sum()\n",
    "bool_series2 = df2.duplicated().sum()\n",
    "print(\"duplicated rows: \" + str(bool_series) + \" | \" + str(bool_series2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated rows: 0 | 0\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated rows\n",
    "df1 = df1.drop_duplicates(keep = 'last')\n",
    "df2 = df2.drop_duplicates(keep = 'last')\n",
    "bool_series = df1.duplicated().sum()\n",
    "bool_series2 = df2.duplicated().sum()\n",
    "print(\"duplicated rows: \" + str(bool_series) + \" | \" + str(bool_series2))\n",
    "\n",
    "# Clear all rows with only 0s:\n",
    "a_series = (df1 != 0).any(axis=1)\n",
    "df1 = df1.loc[a_series]\n",
    "b_series = (df2 != 0).any(axis=1)\n",
    "df2 = df2.loc[b_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute 0's with nan\n",
    "#df1[df1 < 0] = np.nan\n",
    "#df2[df2 < 0] = np.nan\n",
    "\n",
    "#label the dataframes\n",
    "df1['label'] = 'Ransomware'\n",
    "df2['label'] = 'Benign'\n",
    "\n",
    "#join the dataframes into 1 dataframe (df3)\n",
    "frames = [df1, df2]\n",
    "df3 = pd.concat(frames)\n",
    "\n",
    "#shuffle!\n",
    "df3 = df3.sample(frac=1)\n",
    "df1 = df1.sample(frac=1)\n",
    "df2 = df2.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import count_nonzero\n",
    "#estimator=count_nonzero if you want counts, not avg\n",
    "from numpy import count_nonzero\n",
    "\n",
    "sns.barplot(y=df3['USE_SIP'], x = df3['label'], estimator = count_nonzero)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df3['USE_SIP'], y = df3['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize data\n",
    "#df2.describe()\n",
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Validation method\n",
    "# Train and validation set split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# change label to be a category\n",
    "#df3[\"label\"] = df3[\"label\"].astype('category')\n",
    "\n",
    "array = df3.values\n",
    "\n",
    "#All of the non-label columns\n",
    "X = array[:, 0:-1]\n",
    "\n",
    "#label column\n",
    "y = array[:, -1]\n",
    "\n",
    "#USING CHI2 (current (X_new))\n",
    "z = SelectKBest(chi2, k=15)\n",
    "X_new = z.fit_transform(X, y)\n",
    "X_new.shape\n",
    "\n",
    "#Obtain the train/validation datasets on a 80/20 split\n",
    "#TODO same w/ tenfold cross val\n",
    "# compare results\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_new, y, test_size=0.20, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = z.get_support(indices=True)\n",
    "features_df_new = df3.iloc[:,cols]\n",
    "list(features_df_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=12000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC(gamma='auto', max_iter=10000)))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('CNN', MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=16, max_iter = 10000)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "model = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=16, max_iter = 10000)\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an ensamble out of multiple classifiers\n",
    "clf1 = LogisticRegression(solver='liblinear', multi_class='ovr', dual=False, max_iter=12000)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=12)\n",
    "clf3 = DecisionTreeClassifier()\n",
    "clf4 = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=16, max_iter = 100000)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3), ('cnn', clf4)],\n",
    "                        voting='hard')\n",
    "\n",
    "# Make predictions on validation dataset\n",
    "model = eclf\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_validation)\n",
    "\n",
    "# Evaluate predictions\n",
    "print(\"Ensamble accuracy: \" + str(accuracy_score(Y_validation, predictions)))\n",
    "print(\"Matrix: \")\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))\n",
    "\n",
    "# Evaluate classifier on a CV5 cross_val_score\n",
    "for clf, label in zip(\n",
    "    [clf1, clf2, clf3, clf4, eclf],\n",
    "    ['Logistic Regression', 'Random Forest', 'Dec. Tree', 'CNN', 'Ensamble']):\n",
    "    scores = cross_val_score(clf, X_new, y, scoring='accuracy', cv=5)\n",
    "    print(\"Accuracy: %0.5f (+/- %0.5f) [%s]\" %\n",
    "          (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "[ ] VERY DUPLICATED DATA\n",
    "[ ] Run analysis per family\n",
    "\n",
    "[ ] Confusion Matrix\n",
    "[x] Accuracy\n",
    "[x] Precision/Recall\n",
    "[ ] Macro / W. Average\n",
    "\n",
    "[x] Add barchart comparisons of features\n",
    "[x] Feature Engineering / Selection\n",
    "\n",
    "Plot for permissions (top best ones)\n",
    "Compare to papers: \n",
    "    table with # of features\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "320ac9d7d90cb04b1d605a796df630f2fa27669b38d4922559081428401cacbd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
